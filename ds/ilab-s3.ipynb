{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fe615f-974d-4a84-be43-d03b884e20d4",
   "metadata": {},
   "source": [
    "## InstructLab Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a0408-221c-48e4-9d07-33bc4e1f1fd5",
   "metadata": {},
   "source": [
    "The purpose of this repository is to demonstrate how to perform RAFT (Retrieval Augmented Fine Tuning) by using InstructLab & Milvus on RHEL.\n",
    "\n",
    "Fine Tuning: Train Llama-3.2-1B to know about LLaMA 4 by using InstructLab's Synthetic Data Generation.\n",
    "\n",
    "Serving: The fine tuned model is served via vLLM on top of InstructLab.\n",
    "\n",
    "Retrieval Augmented Generation: Integrate organizational context into the fine-tuned model by embedding the document located at rag/DOG.md into Milvus. This document defines appropriate and inappropriate use cases for LLaMA 4 within a dog adoption organization. The Chat bot will answer according to the organizational context.\n",
    "\n",
    "**This has been tested on a Notebook with a single Nvidia L4 GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71acd7d-3d81-44aa-bab5-64440eb7f0d1",
   "metadata": {},
   "source": [
    "Install InstructLab -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ffeaf-37dd-4cc9-8b78-377a4e3d3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install instructlab==0.26.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174ad8e-be21-48df-88be-e1370885ff3d",
   "metadata": {},
   "source": [
    "Install llama-cpp-python in order to utilze the GPU in the system.\n",
    "\n",
    "**This might fail, but this is OK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0e285-900e-4e96-970b-4be395950bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CMAKE_ARGS=\"-DGGML_CUDA=on\" \\\n",
    "  FORCE_CMAKE=1 \\\n",
    "  pip install --no-cache-dir --force-reinstall llama-cpp-python==0.3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e9396-82bf-4537-a2e9-84738eb26d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.26.4 instructlab-training[cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a020a6-5cab-4b0f-80ae-bfe595d0520b",
   "metadata": {},
   "source": [
    "## Verify the installation of InstructLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555f3a4-5de8-4f00-a822-2f1cf8df1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83898d48-4647-4fae-a199-a54a645e9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beddb8-88f8-4d2d-a734-810992ad0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6fc14-0e11-4787-b542-3b80ec03b02b",
   "metadata": {},
   "source": [
    "## Configuring Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4766933-3cd2-445b-8dc1-517b0435fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN=\"<Insert Token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6012b03-46d9-4c2f-91c4-88649bd3be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab config init --non-interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d801e2-9ce1-4a13-9df3-a1095460361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4dc30-cc53-4d1c-ada4-19ec18b42147",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.local/share/instructlab/taxonomy/knowledge/llms/llama/\n",
    "\n",
    "!cp ../sdg/qna.yaml ~/.local/share/instructlab/taxonomy/knowledge/llms/llama/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a050d-f87a-47b3-af43-18e1bc9575d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab taxonomy diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b60fd-1087-4ce8-82ad-750f089e1b05",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331db12-e64e-4dc8-ac3f-b7c7c68d76c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab data generate --num-instructions 500 --enable-serving-output --gpus 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4da545-a450-4c23-a748-5f5fc6a0b794",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b96d7-f1b4-47a6-8fca-84c74ffbdc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model download --repository=meta-llama/Llama-3.2-1B-Instruct --hf-token $HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e3529-f689-45a9-8657-474520c2aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model train --model-path ~/.cache/instructlab/models/meta-llama/Llama-3.2-1B-Instruct --data-path ~/.local/share/instructlab/datasets/2025-06-16_121930/knowledge_train_msgs_2025-06-16T12_19_38.jsonl --device cuda --pipeline accelerated --gpus 1 --num-epochs 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc92bf-85de-40c7-89d3-603e8b1efe1d",
   "metadata": {},
   "source": [
    "## Chat with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62337c3-6a79-4a61-8abf-664cbc9c14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ilab model serve --model-path /home/instruct/.cache/instructlab/models/meta-llama/Llama-3.2-1B-Instruct/ --gpus=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167e08b-2f57-4fd8-ab81-087ae513d6c3",
   "metadata": {},
   "source": [
    "## Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8c9d7-fb92-4a0a-b77b-27ed55c8a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05212f-7b37-4a71-bff3-53a2ff6042dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os, pathlib\n",
    "\n",
    "model_dir = pathlib.Path(\"/opt/app-root/src/.cache/instructlab/models/instructlab/granite-7b-lab\")   # where your .bin / safetensors live\n",
    "bucket     = \"models\"\n",
    "prefix     = \"granite-7b/\"\n",
    "\n",
    "s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=\"url\",\n",
    "        aws_access_key_id='minioadmin',\n",
    "        aws_secret_access_key='minioadmin')\n",
    "\n",
    "for f in model_dir.iterdir():\n",
    "    if f.is_file():\n",
    "        s3.upload_file(str(f), bucket, prefix + f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedbf18f-2773-4add-b598-2819bf567c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
